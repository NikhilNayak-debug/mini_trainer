[tox]
requires = 
    tox>=4
    tox-uv
env_list = py311, py312

[testenv]
# Use uv for package installation and management
runner = uv-venv-runner
uv_seed = true
deps = 
    pytest
    pytest-cov
    ruff
commands = pytest {posargs} -p no:xdist

[testenv:test]
description = Run all tests (includes GPU tests if CUDA is available)
deps = 
    pytest
    pytest-cov
    pytest-mock
    torch>=2.6,<2.8
    ninja
passenv = 
    CUDA_VISIBLE_DEVICES
    CUDA_HOME
    LD_LIBRARY_PATH
commands_pre = 
    # Try to install flash-attn if CUDA is available (non-strict mode)
    python -c "import torch; import sys; sys.exit(0 if torch.cuda.is_available() else 1)" && python tests/gpu_tests/setup_flash_attn.py || python -c "print('CUDA not available or flash-attn setup failed, skipping...')"
commands = 
    # Run all tests, GPU tests will be automatically skipped if CUDA is not available
    pytest {posargs} -p no:xdist

[testenv:test-verbose]
description = Run tests with verbose output, useful for debugging.
commands = pytest -v {posargs} -p no:xdist

[testenv:test-quick]
description = Run tests until first failure, useful for debugging.
commands = pytest -x {posargs} -p no:xdist

[testenv:test-coverage]
description = Run tests with coverage
commands = pytest --cov=mini_trainer --cov-report=html --cov-report=term {posargs}

[testenv:lint]
description = Run linting with ruff
commands = ruff check .

[testenv:lint-fix]
description = Run linting with ruff and fix issues
commands = ruff check --fix .

[testenv:format]
description = Format code with ruff
commands = ruff format .

[testenv:format-check]
description = Check code formatting with ruff
commands = ruff format --check .

[testenv:py311]
description = Run tests on Python 3.11
base_python = python3.11
commands_pre = 
    # Try to install flash-attn if CUDA is available (non-strict mode)
    python -c "import torch; import sys; sys.exit(0 if torch.cuda.is_available() else 1)" && python tests/gpu_tests/setup_flash_attn.py || python -c "print('CUDA not available or flash-attn setup failed, skipping...')"

[testenv:py312]
description = Run tests on Python 3.12
base_python = python3.12
commands_pre = 
    # Try to install flash-attn if CUDA is available (non-strict mode)
    python -c "import torch; import sys; sys.exit(0 if torch.cuda.is_available() else 1)" && python tests/gpu_tests/setup_flash_attn.py || python -c "print('CUDA not available or flash-attn setup failed, skipping...')"


# These are tests for CI so we can run stuff in non-CUDA environments
[testenv:test-non-gpu]
description = Run all non-GPU tests (for CI)
deps = 
    pytest
    pytest-cov
    pytest-mock
setenv = 
    CUDA_VISIBLE_DEVICES = 
commands = pytest tests/ -m "not gpu and not multi_gpu" --ignore=tests/gpu_tests/ -v -p no:xdist --tb=short {posargs}

[testenv:test-non-gpu-coverage]
description = Run all non-GPU tests with coverage reporting
deps = 
    pytest
    pytest-cov
    pytest-mock
setenv = 
    CUDA_VISIBLE_DEVICES = 
commands = pytest tests/ -m "not gpu and not multi_gpu" --ignore=tests/gpu_tests/ -v -p no:xdist --tb=short --cov=src/mini_trainer --cov-report=term-missing --cov-report=xml --cov-report=html {posargs}

[testenv:test-non-gpu-py311]
description = Run non-GPU tests on Python 3.11
base_python = python3.11
deps = 
    pytest
    pytest-cov
    pytest-mock
setenv = 
    CUDA_VISIBLE_DEVICES = 
commands = pytest tests/ -m "not gpu and not multi_gpu" --ignore=tests/gpu_tests/ -v -p no:xdist --tb=short {posargs}

[testenv:test-non-gpu-py312]
description = Run non-GPU tests on Python 3.12
base_python = python3.12
deps = 
    pytest
    pytest-cov
    pytest-mock
setenv = 
    CUDA_VISIBLE_DEVICES = 
commands = pytest tests/ -m "not gpu and not multi_gpu" --ignore=tests/gpu_tests/ -v -p no:xdist --tb=short {posargs}

[testenv:test-gpu]
description = Run all GPU tests (requires CUDA, flash-attn optional)
base_python = python3.12
deps = 
    pytest
    pytest-cov
    torch>=2.6,<2.8
    ninja
passenv = 
    CUDA_VISIBLE_DEVICES
    CUDA_HOME
    LD_LIBRARY_PATH
    NCCL_DEBUG
# Install flash-attn after torch and ninja are available
commands_pre = 
    python -c "import sys; sys.exit(0) if __import__('importlib.util').util.find_spec('flash_attn') else None"
    python tests/gpu_tests/setup_flash_attn.py --strict
# Run tests sequentially to avoid GPU resource conflicts
commands = pytest tests/gpu_tests -v --tb=short -p no:xdist {posargs}


[testenv:test-gpu-py311]
description = Run GPU tests marked with @pytest.mark.gpu on Python 3.11
base_python = python3.11
deps = 
    pytest
    pytest-cov
    torch>=2.6,<2.8
    ninja
passenv = 
    CUDA_VISIBLE_DEVICES
    CUDA_HOME
    LD_LIBRARY_PATH
# Install flash-attn after torch and ninja are available
commands_pre = 
    python -c "import sys; sys.exit(0) if __import__('importlib.util').util.find_spec('flash_attn') else None"
    python tests/gpu_tests/setup_flash_attn.py --strict
commands = pytest tests/gpu_tests -v -p no:xdist {posargs}

[testenv:test-gpu-py312]
description = Run GPU tests marked with @pytest.mark.gpu on Python 3.12
base_python = python3.12
deps = 
    pytest
    pytest-cov
    torch>=2.6,<2.8
    ninja
passenv = 
    CUDA_VISIBLE_DEVICES
    CUDA_HOME
    LD_LIBRARY_PATH
# Install flash-attn after torch and ninja are available
commands_pre = 
    python -c "import sys; sys.exit(0) if __import__('importlib.util').util.find_spec('flash_attn') else None"
    python tests/gpu_tests/setup_flash_attn.py --strict
# run sequentially
commands = pytest tests/gpu_tests -v -p no:xdist {posargs}
